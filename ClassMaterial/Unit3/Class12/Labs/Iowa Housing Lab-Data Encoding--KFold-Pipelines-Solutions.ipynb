{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iowa Housing Lab -- Data Encoding\n",
    "\n",
    "Welcome!! This lab will continue where we left off last class -- building a regression model, but this time with new features added in -- using cross validation to evaluate our scores, and building our encoding steps into pipelines.\n",
    "\n",
    "**Important:** A summary of each of the columns in this dataset, and what their values mean, can be found here: https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1).  Load in your data set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import category_encoders as ce\n",
    "from sklearn.pipeline import make_pipeline\n",
    "df = pd.read_csv('../../data/iowa_train2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2).  There are missing values throughout this dataset.  Fill them in appropriately**\n",
    "\n",
    "We already covered this in class, but to give you a reminder:\n",
    "\n",
    " - Are the missing values random or not?\n",
    " - Encode them as missing if possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll first mark the missing values as such\n",
    "def denote_null_values(df):\n",
    "    empty_cols_query = df.isnull().sum() > 0\n",
    "    empty_df_cols = df.loc[:, empty_cols_query].columns.tolist()\n",
    "    for col in empty_df_cols:\n",
    "        col_name = f\"{col}_missing\"\n",
    "        df[col_name] = pd.isnull(df[col])\n",
    "    return df\n",
    "\n",
    "df = denote_null_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "# they are not random -- will fill with 'None' and 0\n",
    "missing_cols_query = df.isnull().sum() > 0\n",
    "missing_cols_num = df.loc[:, missing_cols_query].select_dtypes(include=np.number).columns.tolist()\n",
    "missing_cols_cat = df.loc[:, missing_cols_query].select_dtypes(include=np.object).columns.tolist()\n",
    "df[missing_cols_num] = df[missing_cols_num].fillna(0)\n",
    "df[missing_cols_cat] = df[missing_cols_cat].fillna('None')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3): Create A Pipeline With Your Model And The Column Encoder of Your Choice**\n",
    "\n",
    "For now, you can choose which encoding technique you would want to use.  Later on you'll go back and check to see if it made a large difference.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here\n",
    "pipe = make_pipeline(ce.OrdinalEncoder(), GradientBoostingRegressor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4).  Create A Training & Test Set**\n",
    "\n",
    "Re-use the same settings that we've completed previously in class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here\n",
    "X = df.drop('SalePrice', axis=1)\n",
    "y = df['SalePrice']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1985)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5).  Get An Initial 10 Fold Cross Validation Score**\n",
    "\n",
    "This will be your initial baseline for improving your score.  Use your pipeline in this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here\n",
    "cv_scores = cross_val_score(estimator=pipe, X=X_train, y=y_train, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.89485054, 0.88229815, 0.88887342, 0.84339908, 0.88340465,\n",
       "       0.87471986, 0.93623092, 0.60320311, 0.82593033, 0.87250408])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# our scores\n",
    "cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8505414144791285"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average\n",
    "cv_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6).  Do Parameter Exploration With Your Model To Find the Best Combination On Your Validation Set**\n",
    "\n",
    "Use pipelines here to make processing easier.\n",
    "\n",
    "Parameters to explore:\n",
    "\n",
    " - `n_estimators` (would not go above 1000 for now)\n",
    " - `max_depth`  (usually up to 5 levels deep is okay)\n",
    " - `learning_rate` (.001 - 0.1 is a good range)\n",
    " \n",
    "It's a good idea to refer to previous lab exercises to see how best to do this.\n",
    "\n",
    "Use 5 folds to get your validation score (this is for time)\n",
    "\n",
    "**Hint:** Use the `steps` attribute in the pipeline to grab the `GradientBoostingRegressor()` in your pipeline and set its params.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8685628826441191, 100, 4, 0.1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your answer here\n",
    "num_trees = [100, 500, 1000]\n",
    "max_depth = [2, 3, 4]\n",
    "learning_rate = [.001, .01, .1]\n",
    "cv_scores = []\n",
    "\n",
    "for tree in num_trees:\n",
    "    for depth in max_depth:\n",
    "        for rate in learning_rate:\n",
    "            pipe.steps[1][1].set_params(n_estimators=tree, max_depth=depth, learning_rate=rate)\n",
    "            score = cross_val_score(estimator=pipe, X=X_train, y=y_train, cv=5)\n",
    "            cv_scores.append((score.mean(), tree, depth, rate))\n",
    "            \n",
    "max(cv_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 7).  Take the *best* parameter versions and fit this on your *entire* training set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('ordinalencoder',\n",
       "                 OrdinalEncoder(cols=['MSZoning', 'Neighborhood', 'GarageType',\n",
       "                                      'GarageFinish'],\n",
       "                                drop_invariant=False, handle_missing='value',\n",
       "                                handle_unknown='value',\n",
       "                                mapping=[{'col': 'MSZoning',\n",
       "                                          'data_type': dtype('O'),\n",
       "                                          'mapping': RL         1\n",
       "RM         2\n",
       "RH         3\n",
       "FV         4\n",
       "C (all)    5\n",
       "NaN       -2\n",
       "dtype: int64},\n",
       "                                         {'col': 'Neighborhood',\n",
       "                                          'data_type': dtype('O'),\n",
       "                                          'mapping': SWISU       1\n",
       "NAm...\n",
       "                                           learning_rate=0.1, loss='ls',\n",
       "                                           max_depth=4, max_features=None,\n",
       "                                           max_leaf_nodes=None,\n",
       "                                           min_impurity_decrease=0.0,\n",
       "                                           min_impurity_split=None,\n",
       "                                           min_samples_leaf=1,\n",
       "                                           min_samples_split=2,\n",
       "                                           min_weight_fraction_leaf=0.0,\n",
       "                                           n_estimators=100,\n",
       "                                           n_iter_no_change=None,\n",
       "                                           presort='deprecated',\n",
       "                                           random_state=None, subsample=1.0,\n",
       "                                           tol=0.0001, validation_fraction=0.1,\n",
       "                                           verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your answer here\n",
    "pipe.steps[1][1].set_params(n_estimators=100, max_depth=4, learning_rate=0.1)\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 8).  Score the model on your test set**\n",
    "\n",
    "How did the two compare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8718705792693213"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your answer here\n",
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
